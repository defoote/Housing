{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Neural Net w/Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Data/train.csv',index_col=0)\n",
    "test = pd.read_csv('./Data/test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get full columns and only use this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for col in train.columns:\n",
    "    if train[col].count() == 1460:\n",
    "        cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[cols]\n",
    "test = test[cols[:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dummy columns for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat so that train and test have same number of columns since test is missing some values in a few columns\n",
    "temp = pd.get_dummies(pd.concat([train,test],sort=False))\n",
    "train = temp.iloc[:1460]\n",
    "test = temp.iloc[1460:].drop(['SalePrice'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train_scaler = MinMaxScaler()\n",
    "test_scaler = MinMaxScaler()\n",
    "train = pd.DataFrame(train_scaler.fit_transform(train),columns=train.columns)\n",
    "test = pd.DataFrame(test_scaler.fit_transform(test),columns=test.columns,index=np.arange(1461,2920))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train into feature and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.drop(['SalePrice'],axis=1)\n",
    "y = train['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split on Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1022 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1022/1022 [==============================] - 1s 505us/step - loss: 0.0682 - mae: 0.2266 - val_loss: 0.0118 - val_mae: 0.0782\n",
      "Epoch 2/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.0243 - mae: 0.1186 - val_loss: 0.0078 - val_mae: 0.0645\n",
      "Epoch 3/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.0172 - mae: 0.1006 - val_loss: 0.0059 - val_mae: 0.0570\n",
      "Epoch 4/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.0131 - mae: 0.0879 - val_loss: 0.0049 - val_mae: 0.0521\n",
      "Epoch 5/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.0119 - mae: 0.0851 - val_loss: 0.0040 - val_mae: 0.0464\n",
      "Epoch 6/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0775 - val_loss: 0.0037 - val_mae: 0.0445\n",
      "Epoch 7/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.0092 - mae: 0.0743 - val_loss: 0.0037 - val_mae: 0.0446\n",
      "Epoch 8/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.0082 - mae: 0.0689 - val_loss: 0.0035 - val_mae: 0.0432\n",
      "Epoch 9/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.0084 - mae: 0.0719 - val_loss: 0.0033 - val_mae: 0.0410\n",
      "Epoch 10/100\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 0.0084 - mae: 0.0694 - val_loss: 0.0032 - val_mae: 0.0410\n",
      "Epoch 11/100\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.0076 - mae: 0.0681 - val_loss: 0.0031 - val_mae: 0.0381\n",
      "Epoch 12/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.0073 - mae: 0.0670 - val_loss: 0.0031 - val_mae: 0.0379\n",
      "Epoch 13/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.0069 - mae: 0.0651 - val_loss: 0.0032 - val_mae: 0.0367\n",
      "Epoch 14/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.0066 - mae: 0.0634 - val_loss: 0.0031 - val_mae: 0.0372\n",
      "Epoch 15/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.0063 - mae: 0.0630 - val_loss: 0.0030 - val_mae: 0.0343\n",
      "Epoch 16/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.0066 - mae: 0.0648 - val_loss: 0.0032 - val_mae: 0.0365\n",
      "Epoch 17/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.0067 - mae: 0.0653 - val_loss: 0.0032 - val_mae: 0.0362\n",
      "Epoch 18/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.0062 - mae: 0.0614 - val_loss: 0.0032 - val_mae: 0.0349\n",
      "Epoch 19/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.0066 - mae: 0.0621 - val_loss: 0.0030 - val_mae: 0.0336\n",
      "Epoch 20/100\n",
      "1022/1022 [==============================] - 0s 118us/step - loss: 0.0059 - mae: 0.0599 - val_loss: 0.0030 - val_mae: 0.0337\n",
      "Epoch 21/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.0063 - mae: 0.0619 - val_loss: 0.0032 - val_mae: 0.0344\n",
      "Epoch 22/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.0063 - mae: 0.0617 - val_loss: 0.0033 - val_mae: 0.0344\n",
      "Epoch 23/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.0050 - mae: 0.0565 - val_loss: 0.0033 - val_mae: 0.0342\n",
      "Epoch 24/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.0059 - mae: 0.0590 - val_loss: 0.0032 - val_mae: 0.0328\n",
      "Epoch 25/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.0059 - mae: 0.0590 - val_loss: 0.0035 - val_mae: 0.0353\n",
      "Epoch 26/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.0052 - mae: 0.0565 - val_loss: 0.0033 - val_mae: 0.0341\n",
      "Epoch 27/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.0047 - mae: 0.0538 - val_loss: 0.0034 - val_mae: 0.0336\n",
      "Epoch 28/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.0051 - mae: 0.0559 - val_loss: 0.0032 - val_mae: 0.0325\n",
      "Epoch 29/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.0047 - mae: 0.0528 - val_loss: 0.0034 - val_mae: 0.0328\n",
      "Epoch 30/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.0049 - mae: 0.0534 - val_loss: 0.0033 - val_mae: 0.0303\n",
      "Epoch 31/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.0052 - mae: 0.0550 - val_loss: 0.0031 - val_mae: 0.0317\n",
      "Epoch 32/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.0045 - mae: 0.0525 - val_loss: 0.0030 - val_mae: 0.0310\n",
      "Epoch 33/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.0048 - mae: 0.0530 - val_loss: 0.0034 - val_mae: 0.0347\n",
      "Epoch 34/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.0043 - mae: 0.0508 - val_loss: 0.0032 - val_mae: 0.0322\n",
      "Epoch 35/100\n",
      "1022/1022 [==============================] - 0s 129us/step - loss: 0.0043 - mae: 0.0507 - val_loss: 0.0032 - val_mae: 0.0311\n",
      "Epoch 36/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.0040 - mae: 0.0488 - val_loss: 0.0034 - val_mae: 0.0310\n",
      "Epoch 37/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.0041 - mae: 0.0505 - val_loss: 0.0033 - val_mae: 0.0299\n",
      "Epoch 38/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.0040 - mae: 0.0490 - val_loss: 0.0035 - val_mae: 0.0343\n",
      "Epoch 39/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0033 - val_mae: 0.0295\n",
      "Epoch 40/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.0036 - mae: 0.0465 - val_loss: 0.0032 - val_mae: 0.0297\n",
      "Epoch 41/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.0039 - mae: 0.0484 - val_loss: 0.0033 - val_mae: 0.0294\n",
      "Epoch 42/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.0035 - mae: 0.0467 - val_loss: 0.0035 - val_mae: 0.0302\n",
      "Epoch 43/100\n",
      "1022/1022 [==============================] - 0s 127us/step - loss: 0.0043 - mae: 0.0494 - val_loss: 0.0038 - val_mae: 0.0311\n",
      "Epoch 44/100\n",
      "1022/1022 [==============================] - 0s 134us/step - loss: 0.0038 - mae: 0.0480 - val_loss: 0.0037 - val_mae: 0.0345\n",
      "Epoch 45/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.0039 - mae: 0.0481 - val_loss: 0.0035 - val_mae: 0.0301\n",
      "Epoch 46/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.0035 - mae: 0.0453 - val_loss: 0.0037 - val_mae: 0.0327\n",
      "Epoch 47/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.0035 - mae: 0.0456 - val_loss: 0.0034 - val_mae: 0.0291\n",
      "Epoch 48/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.0035 - mae: 0.0446 - val_loss: 0.0034 - val_mae: 0.0287\n",
      "Epoch 49/100\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 0.0032 - mae: 0.0444 - val_loss: 0.0037 - val_mae: 0.0314\n",
      "Epoch 50/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.0036 - mae: 0.0461 - val_loss: 0.0035 - val_mae: 0.0316\n",
      "Epoch 51/100\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 0.0035 - mae: 0.0436 - val_loss: 0.0035 - val_mae: 0.0297\n",
      "Epoch 52/100\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 0.0033 - mae: 0.0437 - val_loss: 0.0035 - val_mae: 0.0294\n",
      "Epoch 53/100\n",
      "1022/1022 [==============================] - 0s 120us/step - loss: 0.0032 - mae: 0.0437 - val_loss: 0.0035 - val_mae: 0.0290\n",
      "Epoch 54/100\n",
      "1022/1022 [==============================] - 0s 114us/step - loss: 0.0031 - mae: 0.0431 - val_loss: 0.0036 - val_mae: 0.0288\n",
      "Epoch 55/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.0030 - mae: 0.0435 - val_loss: 0.0037 - val_mae: 0.0305\n",
      "Epoch 56/100\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 0.0030 - mae: 0.0420 - val_loss: 0.0035 - val_mae: 0.0284\n",
      "Epoch 57/100\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 0.0034 - mae: 0.0424 - val_loss: 0.0034 - val_mae: 0.0289\n",
      "Epoch 58/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.0030 - mae: 0.0425 - val_loss: 0.0035 - val_mae: 0.0281\n",
      "Epoch 59/100\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 0.0030 - mae: 0.0410 - val_loss: 0.0036 - val_mae: 0.0288\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 116us/step - loss: 0.0032 - mae: 0.0426 - val_loss: 0.0040 - val_mae: 0.0295\n",
      "Epoch 61/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.0029 - mae: 0.0412 - val_loss: 0.0037 - val_mae: 0.0296\n",
      "Epoch 62/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.0028 - mae: 0.0406 - val_loss: 0.0039 - val_mae: 0.0334\n",
      "Epoch 63/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.0031 - mae: 0.0417 - val_loss: 0.0038 - val_mae: 0.0305\n",
      "Epoch 64/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.0028 - mae: 0.0400 - val_loss: 0.0037 - val_mae: 0.0281\n",
      "Epoch 65/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.0027 - mae: 0.0399 - val_loss: 0.0039 - val_mae: 0.0299\n",
      "Epoch 66/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.0029 - mae: 0.0404 - val_loss: 0.0038 - val_mae: 0.0286\n",
      "Epoch 67/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.0026 - mae: 0.0399 - val_loss: 0.0039 - val_mae: 0.0301\n",
      "Epoch 68/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.0026 - mae: 0.0391 - val_loss: 0.0036 - val_mae: 0.0286\n",
      "Epoch 69/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.0029 - mae: 0.0403 - val_loss: 0.0038 - val_mae: 0.0314\n",
      "Epoch 70/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.0027 - mae: 0.0395 - val_loss: 0.0037 - val_mae: 0.0288\n",
      "Epoch 71/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.0026 - mae: 0.0386 - val_loss: 0.0040 - val_mae: 0.0323\n",
      "Epoch 72/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.0027 - mae: 0.0394 - val_loss: 0.0037 - val_mae: 0.0273\n",
      "Epoch 73/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.0027 - mae: 0.0385 - val_loss: 0.0041 - val_mae: 0.0329\n",
      "Epoch 74/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.0025 - mae: 0.0374 - val_loss: 0.0038 - val_mae: 0.0301\n",
      "Epoch 75/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.0024 - mae: 0.0377 - val_loss: 0.0038 - val_mae: 0.0303\n",
      "Epoch 76/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.0023 - mae: 0.0372 - val_loss: 0.0039 - val_mae: 0.0325\n",
      "Epoch 77/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.0022 - mae: 0.0351 - val_loss: 0.0037 - val_mae: 0.0294\n",
      "Epoch 78/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.0023 - mae: 0.0376 - val_loss: 0.0036 - val_mae: 0.0274\n",
      "Epoch 79/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.0020 - mae: 0.0357 - val_loss: 0.0038 - val_mae: 0.0296\n",
      "Epoch 80/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.0022 - mae: 0.0369 - val_loss: 0.0039 - val_mae: 0.0296\n",
      "Epoch 81/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.0027 - mae: 0.0381 - val_loss: 0.0039 - val_mae: 0.0283\n",
      "Epoch 82/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.0023 - mae: 0.0365 - val_loss: 0.0039 - val_mae: 0.0304\n",
      "Epoch 83/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.0024 - mae: 0.0375 - val_loss: 0.0039 - val_mae: 0.0292\n",
      "Epoch 84/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.0024 - mae: 0.0365 - val_loss: 0.0037 - val_mae: 0.0279\n",
      "Epoch 85/100\n",
      "1022/1022 [==============================] - 0s 104us/step - loss: 0.0021 - mae: 0.0353 - val_loss: 0.0041 - val_mae: 0.0340\n",
      "Epoch 86/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.0020 - mae: 0.0339 - val_loss: 0.0038 - val_mae: 0.0295\n",
      "Epoch 87/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.0020 - mae: 0.0345 - val_loss: 0.0037 - val_mae: 0.0276\n",
      "Epoch 88/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.0028 - mae: 0.0367 - val_loss: 0.0040 - val_mae: 0.0301\n",
      "Epoch 89/100\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 0.0027 - mae: 0.0355 - val_loss: 0.0037 - val_mae: 0.0298\n",
      "Epoch 90/100\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 0.0021 - mae: 0.0338 - val_loss: 0.0035 - val_mae: 0.0286\n",
      "Epoch 91/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.0020 - mae: 0.0339 - val_loss: 0.0034 - val_mae: 0.0283\n",
      "Epoch 92/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.0020 - mae: 0.0334 - val_loss: 0.0039 - val_mae: 0.0325\n",
      "Epoch 93/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.0020 - mae: 0.0334 - val_loss: 0.0039 - val_mae: 0.0288\n",
      "Epoch 94/100\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 0.0022 - mae: 0.0339 - val_loss: 0.0040 - val_mae: 0.0312\n",
      "Epoch 95/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.0023 - mae: 0.0356 - val_loss: 0.0036 - val_mae: 0.0276\n",
      "Epoch 96/100\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 0.0020 - mae: 0.0333 - val_loss: 0.0038 - val_mae: 0.0286\n",
      "Epoch 97/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.0019 - mae: 0.0327 - val_loss: 0.0040 - val_mae: 0.0297\n",
      "Epoch 98/100\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 0.0019 - mae: 0.0321 - val_loss: 0.0040 - val_mae: 0.0294\n",
      "Epoch 99/100\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 0.0020 - mae: 0.0325 - val_loss: 0.0039 - val_mae: 0.0296\n",
      "Epoch 100/100\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 0.0018 - mae: 0.0325 - val_loss: 0.0043 - val_mae: 0.0300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x13ee4e210>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation='relu',input_dim=215))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='Adam',loss='mse',metrics=['mae'])\n",
    "\n",
    "model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test portion of the Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 0s 43us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.004253175420065721, 0.029997803270816803]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13f0af150>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(pred,y_test)\n",
    "plt.plot(np.arange(0,0.5,0.01),np.arange(0,0.5,0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions for Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test)\n",
    "pred = [x[0] for x in pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Scaling to get real numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "submission = train.iloc[1460:]\n",
    "submission['SalePrice'] = pred\n",
    "pred = pd.DataFrame(train_scaler.inverse_transform(submission),columns=submission.columns)['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(enumerate(pred)),columns=['Id','SalePrice']).set_index('Id')\n",
    "submission.index += 1460+1\n",
    "submission.fillna(value=submission['SalePrice'].mean(),inplace=True)\n",
    "submission.to_csv('./submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model if wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./Models/Submission_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
